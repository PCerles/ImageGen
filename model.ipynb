{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "from caffe.proto import caffe_pb2\n",
    "from caffe import layers as L, to_proto\n",
    "from caffe import params as P\n",
    "import numpy as np\n",
    "import random, sys, time, os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU_id = 0\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Parameters....\n",
    "CROP_SIZE = 96 # REPLACE\n",
    "BATCH_SIZE = 128 #REPLACE\n",
    "IMAGE_ROOT = \"data/images/\" #REPLACE\n",
    "BIAS_CONSTANT = 0\n",
    "DISCRIMINATOR_NET_PATH = \"discriminator-net.prototxt\"\n",
    "GENERATOR_NET_PATH = \"generator-net.prototxt\"\n",
    "SOLVER_PATH = \"solver.prototxt\"\n",
    "\n",
    "#Learning Parameters\n",
    "weight_param = dict(lr_mult=1, decay_mult=1)\n",
    "bias_param   = dict(lr_mult=2, decay_mult=0)\n",
    "learned_param = [weight_param, bias_param]\n",
    "conv_filler = dict(type='xavier')\n",
    "const_filler = dict(type='constant', value=BIAS_CONSTANT)\n",
    "fc_filler = dict(type='xavier')\n",
    "\n",
    "#Net Parameters (following TensorFlow implementation)\n",
    "gf_dim = 64 # Dimension of gen filters in first conv layer. [64]\n",
    "df_dim = 64 # Dimension of discrim filters in first conv layer. [64]\n",
    "dfc_dim = 1024 # Dimension of discrim units for fully connected layer. [1024]\n",
    "gfc_dim = 1024 # Dimension of gen units for fully connected layer. [1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu_with_batchnorm(bottom, ks, nout, stride=1, pad=1, group=1,weight_filler=conv_filler, bias_filler=const_filler):\n",
    "    conv = L.Convolution(bottom,\n",
    "                         kernel_size=ks,\n",
    "                         num_output=nout,\n",
    "                         stride=stride,\n",
    "                         pad=pad,\n",
    "                         group=group,\n",
    "                         param=learned_param,\n",
    "                         weight_filler=weight_filler,\n",
    "                         bias_filler=bias_filler)\n",
    "    bn = L.BatchNorm(conv,param=[dict(lr_mult=0)] * 3) # what is this @Vash\n",
    "    relu = L.ReLU(bn, in_place=True)\n",
    "    return conv, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(bottom, ks, nout, stride=1, pad=1, group=1,weight_filler=conv_filler, bias_filler=const_filler):\n",
    "    conv = L.Convolution(bottom,\n",
    "                         kernel_size=ks,\n",
    "                         num_output=nout,\n",
    "                         stride=stride,\n",
    "                         pad=pad,\n",
    "                         group=group,\n",
    "                         param=learned_param,\n",
    "                         weight_filler=weight_filler,\n",
    "                         bias_filler=bias_filler)\n",
    "    relu = L.ReLU(conv, in_place=True)\n",
    "    return conv, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_linear(bottom, nout,weight_filler=fc_filler, bias_filler=const_filler):\n",
    "    fc = L.InnerProduct(bottom,\n",
    "                        num_output=nout,\n",
    "                        param=learned_param,\n",
    "                        weight_filler=weight_filler,\n",
    "                        bias_filler=bias_filler)\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_relu(bottom, nout,weight_filler=fc_filler, bias_filler=const_filler):\n",
    "    fc = L.InnerProduct(bottom,\n",
    "                        num_output=nout,\n",
    "                        param=learned_param,\n",
    "                        weight_filler=weight_filler,\n",
    "                        bias_filler=bias_filler)\n",
    "    relu = L.ReLU(fc, in_place=True)\n",
    "    return fc, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_sigmoid(bottom, nout,weight_filler=fc_filler, bias_filler=const_filler):\n",
    "    fc = L.InnerProduct(bottom,\n",
    "                        num_output=nout,\n",
    "                        param=learned_param,\n",
    "                        weight_filler=weight_filler,\n",
    "                        bias_filler=bias_filler)\n",
    "    relu = L.Sigmoid(fc, in_place=True)\n",
    "    return fc, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape(bottom, dim1, dim2, dim3, dim4=-1):\n",
    "    param = {shape: [dim1, dim2, dim3, dim4]} # check syntax\n",
    "    r = L.Reshape(bottom,\n",
    "                  reshape_param=param)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv2d_relu_batchnorm(bottom, ks, nout, stride=2, pad=1, group=1,weight_filler=conv_filler, bias_filler=const_filler):\n",
    "    \"\"\"Accepts same parameters as convolutional layer, but everything is backwards\n",
    "    https://github.com/carpedm20/DCGAN-tensorflow/blob/master/ops.py#L72 <--- (???)\n",
    "    \"\"\"\n",
    "    deconv = L.Deconvolution(bottom,\n",
    "                             kernel_size=ks,\n",
    "                             num_output=nout,\n",
    "                             stride=stride,\n",
    "                             pad=pad,\n",
    "                             group=group,\n",
    "                             param=learned_param,\n",
    "                             weight_filler=weight_filler,\n",
    "                             bias_filler=bias_filler)\n",
    "    bn = L.BatchNorm(deconv,param=[dict(lr_mult=0)] * 3) # what is this @Vash\n",
    "    relu = L.ReLU(bn, in_place=True)\n",
    "    return deconv, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv2d_tanh(bottom, ks, nout, stride=2, pad=1, group=1,weight_filler=conv_filler, bias_filler=const_filler):\n",
    "    \"\"\"Accepts same parameters as convolutional layer, but everything is backwards\n",
    "    https://github.com/carpedm20/DCGAN-tensorflow/blob/master/ops.py#L72 <--- (???)\n",
    "    \"\"\"\n",
    "    deconv = L.Deconvolution(bottom,\n",
    "                             kernel_size=ks,\n",
    "                             num_output=nout,\n",
    "                             stride=stride,\n",
    "                             pad=pad,\n",
    "                             group=group,\n",
    "                             param=learned_param,\n",
    "                             weight_filler=weight_filler,\n",
    "                             bias_filler=bias_filler)\n",
    "    tanh = L.TanH(deconv, in_place=True)\n",
    "    return deconv, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(data):\n",
    "    \"\"\"Discriminator in the DC-GAN setup. Originally follows TensorFlow implementation \n",
    "    https://github.com/carpedm20/DCGAN-tensorflow/blob/master/model.py#L184\n",
    "    \n",
    "    Python syntax based on:\n",
    "    https://github.com/BVLC/caffe/blob/master/examples/pycaffe/caffenet.py\n",
    "    \n",
    "    Args:\n",
    "        data: an input image, either from the original dataset or the generator\n",
    "    \n",
    "    Returns:\n",
    "        Caffe net prototxt\n",
    "    \n",
    "    \"\"\"\n",
    "    cov0, relu0 = conv_relu(data, ks=5, nout=df_dim, stride=2)\n",
    "    conv1, relu1 = conv_relu_with_batchnorm(relu0, ks=5, nout=df_dim * 2, stride=2)\n",
    "    conv2, relu2 = conv_relu_with_batchnorm(relu1, ks=5, nout=df_dim * 4, stride=2)\n",
    "    conv3, relu3 = conv_relu_with_batchnorm(relu2, ks=5, nout=df_dim* 8 , stride=2)\n",
    "    fc4, sigmoid4 = fc_sigmoid(n.relu3, 1)\n",
    "                       \n",
    "    return to_proto(sigmoid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, y):\n",
    "    \"\"\"Generator in DC-GAN setup. Originally follows TensorFlow implementation\n",
    "    https://github.com/carpedm20/DCGAN-tensorflow/blob/master/model.py#L212\n",
    "    They seem to be conditioning every step of the way\n",
    "    \n",
    "    Args:\n",
    "        z: input noise, generated by sampler\n",
    "        y: conditioning vector, a caption embedding\n",
    "    \n",
    "    Returns:\n",
    "        Caffe net prototxt\n",
    "    \"\"\"\n",
    "    z = np.concatenate(z, y) #forms one long vector out of z, y\n",
    "    # pre-processing to turn into a larger feature vector\n",
    "    fc1 = fc_linear(z, gf_dim * 8 * 4 * 4)\n",
    "    relu1 = L.ReLU(L.BatchNorm(reshape(fc1,-1, 4, 4, gf_dim * 8), param=[dict(lr_mult=0)] * 3), in_place=True)\n",
    "    \n",
    "    deconv2, relu2 = deconv2d_relu_batchnorm(relu1, ks=8, nout=df_dim *4, stride=2)\n",
    "    deconv3, relu3 = deconv2d_relu_batchnorm(relu2, ks=16, nout=df_dim *2, stride=2)\n",
    "    deconv4, relu4 = deconv2d_relu_batchnorm(relu3, ks=32, nout=df_dim, stride=2)\n",
    "    \n",
    "    tanh5 = deconv2d_tanh(relu4, ks=64, nout=3, stride=2)\n",
    "    \n",
    "    return to_proto(tanh5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
